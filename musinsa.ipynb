{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yanolja 리뷰 크롤링 및 분석\n",
    "\n",
    "이번 노트북에서는 Selenium을 사용하여 Yanolja의 호텔 리뷰 페이지에서 데이터를 크롤링하고, 수집한 데이터에 대해 분석을 진행합니다. 이 과정에서는 웹페이지 로드, 데이터 추출, 텍스트 처리 및 분석 결과를 Excel 파일로 저장하는 작업을 포함합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1단계: Selenium으로 웹페이지 로드\n",
    "\n",
    "Selenium을 사용하여 Yanolja 리뷰 페이지를 로드하고, 스크롤을 내려서 더 많은 데이터를 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Using cached selenium-4.30.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\user\\anaconda3\\envs\\slop\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Using cached trio-0.29.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Using cached trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\user\\anaconda3\\envs\\slop\\lib\\site-packages (from selenium) (2025.1.31)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\user\\anaconda3\\envs\\slop\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\user\\anaconda3\\envs\\slop\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\user\\anaconda3\\envs\\slop\\lib\\site-packages (from trio~=0.17->selenium) (25.3.0)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\anaconda3\\envs\\slop\\lib\\site-packages (from trio~=0.17->selenium) (3.10)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\user\\anaconda3\\envs\\slop\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\user\\anaconda3\\envs\\slop\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\anaconda3\\envs\\slop\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\user\\anaconda3\\envs\\slop\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Using cached selenium-4.30.0-py3-none-any.whl (9.4 MB)\n",
      "Using cached trio-0.29.0-py3-none-any.whl (492 kB)\n",
      "Using cached trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Installing collected packages: sortedcontainers, wsproto, pysocks, outcome, trio, trio-websocket, selenium\n",
      "Successfully installed outcome-1.3.0.post0 pysocks-1.7.1 selenium-4.30.0 sortedcontainers-2.4.0 trio-0.29.0 trio-websocket-0.12.2 wsproto-1.2.0\n",
      "Collecting bs4\n",
      "  Using cached bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\anaconda3\\envs\\slop\\lib\\site-packages (from bs4) (4.13.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\anaconda3\\envs\\slop\\lib\\site-packages (from beautifulsoup4->bs4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\user\\anaconda3\\envs\\slop\\lib\\site-packages (from beautifulsoup4->bs4) (4.12.2)\n",
      "Using cached bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.2\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\envs\\slop\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\user\\anaconda3\\envs\\slop\\lib\\site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\envs\\slop\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\envs\\slop\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\envs\\slop\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\slop\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install bs4\n",
    "!pip install pandas\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# Selenium 드라이버 설정 (Chrome 사용)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Yanolja 리뷰 페이지로 이동\n",
    "url = 'https://www.musinsa.com/search/goods?keyword=%EB%B0%98%ED%8C%94&keywordType=popular&gf=A'\n",
    "######## your code here ########\n",
    "driver.get(url)\n",
    "# 페이지 로딩을 위해 대기\n",
    "time.sleep(5)\n",
    "\n",
    "# 스크롤 설정: 페이지 하단까지 스크롤을 내리기\n",
    "scroll_count = 5  # 스크롤 횟수 설정\n",
    "for _ in range(scroll_count):\n",
    "    ######## your code here ########\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(1)  # 스크롤 이후 대기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2단계: 페이지 소스 가져오기\n",
    "웹페이지의 HTML 소스를 가져와서 BeautifulSoup을 사용해 데이터를 파싱합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 웹페이지 소스 가져오기\n",
    "page_source = driver.page_source\n",
    "\n",
    "# BeautifulSoup를 사용하여 HTML 파싱\n",
    "soup = BeautifulSoup(page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3단계: 리뷰 텍스트 추출\n",
    "리뷰 텍스트를 추출하고 불필요한 공백이나 줄 바꿈을 제거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['( 2PACK ) 퓨어코튼 레이어드 체인 반팔티',\n",
       " 'Rowdy Basketball League T-Shirt_Oatmeal',\n",
       " '[리뉴얼 ver.] 린넨 카라 하프 니트 - 9 COLOR',\n",
       " '오버핏 크루넥 브루클린 반팔 티셔츠 화이트그린',\n",
       " '무지 30수 순면티 2PACK 3컬러',\n",
       " '시그니처 코튼 머슬핏 티셔츠 NSTS01',\n",
       " '(우먼)로고 링거 티셔츠 - 5 COLOR',\n",
       " '릴렉스드 더블코튼 반팔티 ( 7Color )',\n",
       " '20수 스텐다드 핏 프리미엄 코튼 티셔츠',\n",
       " '어게인스트 자수 반팔 티 [블랙]',\n",
       " '오버핏 크루넥 메탈릭 크롬 하트 로고 반팔 티셔츠 화이트',\n",
       " '[S~5XL] DTP 드로잉 반팔 티셔츠_D01 하우스',\n",
       " '[2PACK] CGP 스몰 아치 로고 반팔 티셔츠',\n",
       " '우먼스 플로리 와펜 반팔 티셔츠 블랙',\n",
       " '[무료반품] 드라이 핏 피트니스 티셔츠 M - 블랙:매트 실버 / DX0990-010',\n",
       " '쿨코튼 유넥 반팔 티셔츠 [6 COLOR]',\n",
       " '[3PACK]무지 쿨론 기능성 쿨 반팔 티셔츠 3P',\n",
       " '[4color] 컷오프 로고 반팔 티셔츠 MDTS048',\n",
       " '[2PACK] 로고 반팔 티셔츠 블랙/블랙',\n",
       " '무지 머슬핏 반팔티셔츠 [블랙]',\n",
       " '( 2PACK ) 퓨어코튼 루즈핏 체인 반팔티',\n",
       " '원캣 우먼 레귤러 베이직 티셔츠',\n",
       " 'New MOMO Shirring Short Top (Black)',\n",
       " '[2PACK] 루즈핏 숏슬리브',\n",
       " '우먼 캣츠포에버 레귤러 반팔 티셔츠_화이트',\n",
       " 'WXT013 아이 라이크 휴먼 반팔 티셔츠 (LEMON)',\n",
       " '(우먼)씬 스트라이프 티셔츠 - 6 COLOR',\n",
       " '[2pack] 클래식 머슬핏 무지 반팔 티셔츠',\n",
       " '레드로고 반팔티 [화이트]',\n",
       " 'SORANO Single Logo T-Shirt [2Color]',\n",
       " '풋볼 져지 티셔츠_화이트',\n",
       " 'AEROCOOL S OG TEE 2PACK none',\n",
       " 'Hybrid Tattoo Tee Charcoal',\n",
       " '멘즈 P-6 로고 리스판서빌리-티 / 38504Q5',\n",
       " '무지 머슬핏 반팔티셔츠 [화이트]',\n",
       " '[무료반품] 드라이 핏 UV 하이버스 반팔 피트니스 탑 M - 화이트:블랙 / DV9840-100',\n",
       " '퍼펙트 특양면 무지 오버핏 반팔 티셔츠',\n",
       " '[얼킨 X 나무13] 아티스트 티셔츠 락앤롤 화이트',\n",
       " '스트릿 오버핏 반팔 티셔츠 GT-367',\n",
       " '[3PACK]퓨어코튼 24수 롱기장 레이어드 무지 반팔 티셔츠',\n",
       " 'MILAGRO CREWNECK TEE HEATHER GRAY']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상품 이름추출출\n",
    "################################\n",
    "names_class = driver.find_elements(By.CSS_SELECTOR,\".text-body_13px_reg.sc-eDLKkx.sc-gLLuof.bnDFEJ.fRGBNZ.font-pretendard\")\n",
    "################################\n",
    "names = []\n",
    "\n",
    "# 각 상품 이름름 텍스트 정리 후 추가\n",
    "for name in names_class:\n",
    "    cleaned_text = name.text.strip().replace('\\r', '').replace('\\n', '')\n",
    "    names.append(cleaned_text)\n",
    "\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4단계: 별점 데이터 추출\n",
    "HTML에서 별점 데이터를 추출하고, 각 리뷰의 별점을 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4.8', '4.8', '4.8', '4.8', '4.6', '4.8', '4.5', '4.9', '4.8', '4.8', '4.8', '4.8', '4.8', '4.8', '4.9', '4.9', '4.8', '4.6', '4.8', '5.0', '4.8', '4.8', '4.6', '4.9', '4.8', '4.9', '4.8', '4.9', '4.2', '4.8', '4.8', '4.9', '5.0', '4.4', '4.9', '5.0', '4.9', '4.7', '4.9', '4.8', '4.9']\n",
      "-------------------------------------\n",
      "['4천+', '206', '1만+', '1천+', '233', '6천+', '13', '439', '168', '345', '165', '112', '6천+', '19', '109', '1천+', '1천+', '78', '4', '43', '4천+', '607', '8', '2천+', '168', '19', '5', '1천+', '6', '5', '1천+', '2천+', '7', '5', '36', '41', '1천+', '60', '17', '1천+', '348']\n",
      "-------------------------------------\n",
      "['2.0만', '8.1천', '4.8만', '1.3만', '1.5천', '1.5만', '2.5천', '1.7천', '1.3천', '1.4천', '5.6천', '8.3천', '2.9만', '268', '2.2천', '5.6천', '9.4천', '1.2천', '79', '1.3천', '1.7만', '1.2만', '746', '7.1천', '4.5천', '474', '388', '2.8천', '104', '885', '4.3만', '1.3만', '1.9천', '435', '253', '746', '3.6천', '1.3천', '1.3천', '1.1만', '6.5천']\n"
     ]
    }
   ],
   "source": [
    "# 별점, 별점개수, 좋아요개수 추출\n",
    "ratings = []\n",
    "rating_numbers =[]\n",
    "like_numbers = []\n",
    "################################\n",
    "rating_containers = driver.find_elements(By.CSS_SELECTOR,\".text-etc_11px_reg.text-yellow.font-pretendard\")\n",
    "like_number_containers = driver.find_elements(By.CSS_SELECTOR,\".text-etc_11px_reg.text-red.font-pretendard\")\n",
    "################################\n",
    "\n",
    "for i in range(0, len(rating_containers), 2):\n",
    "    rating = rating_containers[i].text.strip()\n",
    "    rating_count = rating_containers[i+1].text.strip().replace('(', '').replace(')', '')\n",
    "\n",
    "    ratings.append(rating)\n",
    "    rating_numbers.append(rating_count)\n",
    "\n",
    "for j in like_number_containers:\n",
    "    like_numbers.append(j.text.strip())\n",
    "\n",
    "\n",
    "print(ratings)\n",
    "print(\"-------------------------------------\")\n",
    "print(rating_numbers)\n",
    "print(\"-------------------------------------\")\n",
    "print(like_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5단계: 데이터 정리 및 DataFrame으로 변환\n",
    "수집된 데이터를 Pandas DataFrame으로 변환하여 후속 분석을 용이하게 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 상품명, 별점개수, 별점, 좋아요개수를 결합하여 리스트 생성\n",
    "data = list(zip(names, rating_numbers, ratings, like_numbers))\n",
    "\n",
    "# DataFrame으로 변환\n",
    "df_reviews = pd.DataFrame(data, columns=['Name', 'Rating', 'Rating_number', 'Like_number'])\n",
    "df_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9단계: Excel 파일로 저장\n",
    "최종 결과를 Excel 파일로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('musinsa.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in range(len(names)):\n",
    "        name = names[i] if i < len(names) else \"\"\n",
    "        rating = ratings[i] if i < len(ratings) else \"\"\n",
    "        rating_count = rating_numbers[i] if i < len(rating_numbers) else \"\"\n",
    "        like = like_numbers[i] if i < len(like_numbers) else \"\"\n",
    "\n",
    "        line = f\"이름 : {name:<50} 별점개수 : {rating_count:<8} 별점 : {rating:<4} 좋아요 : {like}\\n\"\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10단계: 드라이버 종료\n",
    "크롤링이 끝난 후, Selenium 드라이버를 종료합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드라이버 종료\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
